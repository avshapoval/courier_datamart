# Проект 4

### Структура проекта:
- src/dags: 
    - api_to_stg - загрузка данных из api в stg
    - stg_to_dds - загрузка из stg в dds
    - dds_to_cdm - загрузка из dds в cdm
- src/sql:
    - скрипты для создания таблиц, разделенные по соответствующим слоям директориям

### Требования к системе
- Хранить историю данных с источника AS IS (пер. «как есть»).
В этом случае вероятность ошибки при преобразовании данных уменьшится и можно будет в любой момент времени точно оценить, какие данные были в источнике.
- Стабильность при недоступности одного или нескольких источников.
- Процессы ETL не должны портить данные, если источник не будет доступен.
- Модель данных «Снежинка» в слое DDS.
«Снежинка» позволит быстрее и удобнее формировать новые витрины и соответствующие отчёты. 
- Стабильность при изменении формата данных в источниках.
- Процессы ETL не должны портить данные, если формат данных в источниках изменится.

### Выполненная работа
1. Процесс загрузки данных из источника API в слой **Staging** разрабатываемой системы реализован с помощью DAG-оркестратора Airflow на языке программирования Python. DAG содержит задачи на соответствующую загрузку данных из источника **API**. Исходный код можно найти в src\dags\api_to_stg_dag.py.
2. Процесс загрузки из staging-слоя в слой **Detail Data Storage** реализован с помощью DAG-оркестратора Airflow на языке программирования Python. DAG содержит задачи на соответствующую загрузку данных из таблиц PostgreSQL слоя staging. Исходный код можно найти в src\dags\stg_to_dds_dag.py
3. Процесс загрузки данных в слой **Common Datamarts** реализован аналогично предыдущим пунктам. Источником служат таблицы PostgreSQL слоя Detail Data Storage. Исходный код можно найти в src\dags\dds_to_cdm_dag.py
4. Исходный код для создания таблиц в слоях можно найти в соответствующих слоям директориям в src\sql.

### Подтверждение
Выполнение требований подтверждается результатами тестирования(?)
